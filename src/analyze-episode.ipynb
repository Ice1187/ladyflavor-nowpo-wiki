{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "33fc8598-2d4a-4485-8de2-0222f2448ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pprint import pp\n",
    "from collections import Counter\n",
    "\n",
    "import opencc\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# add the project root to sys.path (assuming your notebook is in `src/`)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from utils.tokenizer import get_ws_model, tokenize_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91c16de5-f366-448c-9c17-1031c1ae7cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = get_ws_model('../utils/ckiptagger/data')\n",
    "s2tw_converter = opencc.OpenCC('s2tw.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cec32905-4707-42dc-b2d1-75f1a71de27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../transcripts/EP60_2 對不起我洗完臉沒把毛巾擰乾我真該死嗚嗚嗚.txt'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = Path('../transcripts/')\n",
    "str(list(d.glob('EP6*.txt'))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "484b2f61-48b1-4fe3-acc4-c3aab96e4990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../transcripts/EP6 罰站就是要背99乘法表！.txt',\n",
      " '../transcripts/EP60_1 面試者：噢我的缺點就是真的太瘦了～.txt',\n",
      " '../transcripts/EP60_2 對不起我洗完臉沒把毛巾擰乾我真該死嗚嗚嗚.txt',\n",
      " '../transcripts/EP61 我是國小潔牙小隊長也要告訴你嗎!?.txt',\n",
      " '../transcripts/EP62 不要再玩詐騙手遊了！.txt',\n",
      " '../transcripts/EP63 生命中有太多大便了！.txt',\n",
      " '../transcripts/EP64 以前的MSN狀態真的太恥啊啊啊啊！本集攝影師老婆代班.txt',\n",
      " '../transcripts/EP65 FB廢片的正確使用方式！？.txt',\n",
      " '../transcripts/EP66 吸管跟免洗筷最討厭了哼！.txt',\n",
      " '../transcripts/EP67 跟阿公去了超奇幻遊覽車進香團？.txt',\n",
      " '../transcripts/EP68 漂泊的童年與吃餿水的故事!?!?｜脆脆漂泊童年第１集.txt',\n",
      " '../transcripts/EP69 我是傳說中的桃園天才小學生｜脆脆漂泊童年第２集.txt',\n",
      " '../transcripts/EP70 嘴破超慘嗚嗚與小時候的舞廳生活!?｜脆脆漂泊童年第３集.txt',\n",
      " '../transcripts/EP71 第一次約會就去泡溫泉 !?.txt',\n",
      " '../transcripts/EP72 漂泊童年飄到了金門的夢幻生活！｜脆脆漂泊童年第４集.txt',\n",
      " '../transcripts/EP73 長這個樣子的店一定雷！？還有土地公竟然不借我發財金ＱＱ.txt',\n",
      " '../transcripts/EP74 想不到我還會耍關刀吧！｜脆脆漂泊童年最終第５集.txt',\n",
      " '../transcripts/EP75 悲慘 ! 強迫推銷血淚史.txt']\n"
     ]
    }
   ],
   "source": [
    "EPISODE_FILES = [str(f) for f in d.glob('EP6*.txt')] + \\\n",
    "                [str(f) for f in d.glob('EP7*.txt')]\n",
    "EPISODE_FILES = sorted(EPISODE_FILES)\n",
    "pp(EPISODE_FILES)\n",
    "\n",
    "#EPISODE_FILES = [\n",
    "#    '../transcripts/EP60_1 面試者：噢我的缺點就是真的太瘦了～.txt',\n",
    "#    '../transcripts/EP60_2 對不起我洗完臉沒把毛巾擰乾我真該死嗚嗚嗚.txt',\n",
    "#    '../transcripts/EP61 我是國小潔牙小隊長也要告訴你嗎!?.txt',\n",
    "#    '../transcripts/EP62 不要再玩詐騙手遊了！.txt',\n",
    "#    '../transcripts/EP63 生命中有太多大便了！.txt',\n",
    "#    '../transcripts/EP64 以前的MSN狀態真的太恥啊啊啊啊！本集攝影師老婆代班.txt',\n",
    "#    '../transcripts/EP65 FB廢片的正確使用方式！？.txt',\n",
    "#    '../transcripts/EP66 吸管跟免洗筷最討厭了哼！.txt',\n",
    "#    '../transcripts/EP67 跟阿公去了超奇幻遊覽車進香團？.txt',\n",
    "#    '../transcripts/EP68 漂泊的童年與吃餿水的故事!?!?｜脆脆漂泊童年第１集.txt',\n",
    "#    '../transcripts/EP69 我是傳說中的桃園天才小學生｜脆脆漂泊童年第２集.txt',\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b61d109d-f6c5-4ed6-a53a-b4bdb42f8d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/EP6 罰站就是要背99乘法表！.txt done\n",
      "/EP60_1 面試者：噢我的缺點就是真的太瘦了～.txt done\n",
      "/EP60_2 對不起我洗完臉沒把毛巾擰乾我真該死嗚嗚嗚.txt done\n",
      "/EP61 我是國小潔牙小隊長也要告訴你嗎!?.txt done\n",
      "/EP62 不要再玩詐騙手遊了！.txt done\n",
      "/EP63 生命中有太多大便了！.txt done\n",
      "/EP64 以前的MSN狀態真的太恥啊啊啊啊！本集攝影師老婆代班.txt done\n",
      "/EP65 FB廢片的正確使用方式！？.txt done\n",
      "/EP66 吸管跟免洗筷最討厭了哼！.txt done\n",
      "/EP67 跟阿公去了超奇幻遊覽車進香團？.txt done\n",
      "/EP68 漂泊的童年與吃餿水的故事!?!?｜脆脆漂泊童年第１集.txt done\n",
      "/EP69 我是傳說中的桃園天才小學生｜脆脆漂泊童年第２集.txt done\n",
      "/EP70 嘴破超慘嗚嗚與小時候的舞廳生活!?｜脆脆漂泊童年第３集.txt done\n",
      "/EP71 第一次約會就去泡溫泉 !?.txt done\n",
      "/EP72 漂泊童年飄到了金門的夢幻生活！｜脆脆漂泊童年第４集.txt done\n",
      "/EP73 長這個樣子的店一定雷！？還有土地公竟然不借我發財金ＱＱ.txt done\n",
      "/EP74 想不到我還會耍關刀吧！｜脆脆漂泊童年最終第５集.txt done\n",
      "/EP75 悲慘 ! 強迫推銷血淚史.txt done\n",
      "['嗨  大家 好 我 是 翠翠 歡迎 來到 好味 小姐 開束 wszystk 我 要 還 你 原型 沒有 要 對不起', '沒有 要 我 還 以為 你 終於 念對 了', '我 剛剛 本來 有 一點 小 得意 的', '那 你 再 念 一 次 好了', '好味 小姐 開束 wszystk  我 還 你 原型 好 可以 可以', '喔 唸完 了', '我 發現 你們 前面 都 忘記 自我 介紹 了', '那 自我 介紹 就 被 你 打斷 了', '沒有 錯 就是 為什麼 我 會 沒有 自我 介紹', '而且 然後 人家 在 開頭 之前 就 先 自我 介紹']\n",
      "['嗨', '大家', '好', '我', '是', '翠翠', '歡迎', '來到', '好味', '小姐', '開束', 'wszystk', '我', '要', '還', '你', '原型', '沒有', '要', '對不起', '沒有', '要', '我', '還', '以為', '你', '終於', '念對', '了', '我']\n"
     ]
    }
   ],
   "source": [
    "episodes = []\n",
    "\n",
    "for episode_file in EPISODE_FILES:\n",
    "    with open(episode_file, 'r') as f:\n",
    "        sentences = s2tw_converter.convert(f.read().strip()).split('\\n')\n",
    "    tokenized_sentences = tokenize_sentences(sentences, ws)\n",
    "    tokenized_words = [word for sentence in tokenized_sentences for word in sentence.split(' ') if word]\n",
    "    word_set = set(tokenized_words)\n",
    "\n",
    "    episodes.append({\n",
    "        'sentences': tokenized_sentences,\n",
    "        'words': tokenized_words,\n",
    "        'word_set': word_set\n",
    "    })\n",
    "    print(episode_file[episode_file.rfind('/'):], 'done')\n",
    "    \n",
    "print(episodes[0]['sentences'][:10])\n",
    "print(episodes[0]['words'][:30])\n",
    "#print(episodes[0]['word_set'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3fb50a8a-aab8-4e4b-b0b5-ff2e45f0ca40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words: 283666\n",
      "Unique words: 15257\n"
     ]
    }
   ],
   "source": [
    "s = set()\n",
    "for ep in episodes:\n",
    "    s.update(ep['word_set'])\n",
    "    \n",
    "print('Total words:', sum([len(ep['words']) for ep in episodes]))\n",
    "print('Unique words:', len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4efa7a-9096-44f4-906a-4e69e771d196",
   "metadata": {},
   "source": [
    "### Build Stopwords List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "8fa34bf8-5c93-4217-be8d-96a0a588809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [\n",
    "    '的', '你', '我', '他', '她', '它', '牠', '就', '是', '個', '了', '這', '那', '對', '有', '一', '不', '啊', '在', '說',\n",
    "    '很','都','喔','要','會','嗎','好','人','跟','問','欸','嗯','也','來','還','隻','看','把','小','去','被','講','種', '太',\n",
    "    '到', '吧', '沒', '嘿', '做', '上', '啦', '嘛', '又', '大', '先', '哦', '耶', '像', '給', '下', '幫', '兩', '得', '再',\n",
    "    '呢', '次', '想', '多', '錯', '讓', '每', '誰', '幾', '最','從','四','著','話','差','聊','者','整','點','全','才','事',\n",
    "    '片','五','坐','過','舉','份','怕','但','裡','蠻','超','只','能', '天', '用', '三', '件', '中', '誒',\n",
    "    # 名詞\n",
    "    '時候', '東西', '大家', '事情', '我們', '你們', '他們', '牠們','現在', '裡面', '外面', '自己', '感覺', '今天', '地方',\n",
    "    # 代名詞\n",
    "    '這樣', '那樣', '這邊', '那邊','什麼',\n",
    "    # 動詞\n",
    "    '覺得', '想說','知道', '開始','看到', '比較', '記得',\n",
    "    # 形容詞\n",
    "    '一些', '沒有','可以','大概', '之類', '一下', '最後', '不會','不錯', '很多', '突然', '真的', '一定', '直接',\n",
    "    # 副詞\n",
    "    '真的', '就是', '可能','已經','之前','之後', '一直', '好像', '不要', '不行', '後來', '有點', '還是', '應該','不然',\n",
    "    # 連接詞\n",
    "    '然後', '所以', '因為', '但是', '其實', '反正', '而且',\n",
    "    # 常見詞\n",
    "    '為什麼', '怎麼', '這麼', '那麼', '這樣子', '幹嘛',\n",
    "\n",
    "    # 其他\n",
    "    '留言',\n",
    "]\n",
    "\n",
    "filtered_words = [word for ep in episodes for word in ep['words'] if word not in stopwords]\n",
    "word_counts = Counter(filtered_words)\n",
    "\n",
    "#pp(word_counts.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c3b953-c31b-4fae-abe8-5414e5a87f15",
   "metadata": {},
   "source": [
    "### Find Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "dcc1da83-de01-4c61-abcb-3fb4bf8a8dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 6 keywords in episode 1: 小時候, 打電動, 小孩, 說謊, 電視, 遙控器\n",
      "Top 6 keywords in episode 2: 面試, 公司, 工作, 雜草, 董事長, 按摩椅\n",
      "Top 6 keywords in episode 3: 蜈蚣, 蟑螂, 壁虎, 水蟻, 內衣, 馬路\n",
      "Top 6 keywords in episode 4: 刷牙, 牙齒, 舞龍, 牙刷, 舞獅, 布子\n",
      "Top 6 keywords in episode 5: 遊戲, crush, candy, 刷牙, 結牙, 抽到\n",
      "Top 6 keywords in episode 6: 大便, 褲子, 上廁所, t恤, 便秘, 班長\n",
      "Top 6 keywords in episode 7: 告白, 天氣瓶, 咖啡廳, 南灣, msn, 蘿蔔\n",
      "Top 6 keywords in episode 8: 蚊子, 葡萄, 馬蹄, 影片, 牙結屎, 髮型\n",
      "Top 6 keywords in episode 9: 吸管, 筷子, 文字, 菠菜, 胡椒, 登登\n",
      "Top 6 keywords in episode 10: 阿公, 阿嬤, 平板, 奶奶, 步道, 導遊\n",
      "Top 6 keywords in episode 11: 哼哼, 哼哼哼哼, 橘子, 丁香, 桃園, 骨頭\n",
      "Top 6 keywords in episode 12: 老師, 金門, 學校, 蛋餅, 考卷, 第一\n",
      "Top 6 keywords in episode 13: 舌頭, 廣東, 金門, 舞池, 跳舞, 嘴巴\n",
      "Top 6 keywords in episode 14: 北投, 圖書館, 七夕, 蘆筍, 約會, 抽屜\n",
      "Top 6 keywords in episode 15: 金門, 蚵嗲, zone, 阿公, 竹山, 印象\n",
      "Top 6 keywords in episode 16: 雨傘, 土地公, 打工, 登登, 虎姑婆, 竹山\n",
      "Top 6 keywords in episode 17: 老師, 生日, 站起來, 關刀, 馬虎, 宋江鎮\n",
      "Top 6 keywords in episode 18: 推銷, 拒絕, 試聽, 教材, 皮膚, 老師\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF\n",
    "sentences = [' '.join([word for word in ep['words'] if word not in stopwords]) for ep in episodes]\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(sentences)\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Define how many top keywords you want per episode\n",
    "top_n = 6\n",
    "\n",
    "# Iterate over each document (episode)\n",
    "for doc_idx in range(tfidf_matrix.shape[0]):\n",
    "    # Get the row for the document in sparse format\n",
    "    doc = tfidf_matrix[doc_idx]\n",
    "    \n",
    "    # Convert to array and get the top N indices\n",
    "    sorted_indices = doc.toarray()[0].argsort()[::-1]  # Sort by TF-IDF score in descending order\n",
    "    \n",
    "    # Extract the top N words\n",
    "    top_words = [feature_names[i] for i in sorted_indices[:top_n]]\n",
    "    \n",
    "    # Print top keywords for each episode\n",
    "    print(f\"Top {top_n} keywords in episode {doc_idx + 1}: {', '.join(top_words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8ab2ac30-e101-41bd-893f-f92747ad3337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: 0.000*\"哼哼\" + 0.000*\"一樣\" + 0.000*\"發現\" + 0.000*\"時間\"\n",
      "Topic 2: 0.006*\"登登\" + 0.005*\"如果\" + 0.004*\"一樣\" + 0.004*\"雨傘\"\n",
      "Topic 3: 0.005*\"牙齒\" + 0.005*\"老師\" + 0.004*\"刷牙\" + 0.004*\"如果\"\n",
      "Topic 4: 0.013*\"吸管\" + 0.009*\"筷子\" + 0.006*\"討厭\" + 0.006*\"上面\"\n",
      "Topic 5: 0.000*\"發現\" + 0.000*\"一樣\" + 0.000*\"一點\" + 0.000*\"如果\"\n",
      "Topic 6: 0.000*\"小孩\" + 0.000*\"一樣\" + 0.000*\"發現\" + 0.000*\"老師\"\n",
      "Topic 7: 0.008*\"影片\" + 0.006*\"OK\" + 0.005*\"問題\" + 0.005*\"蚊子\"\n",
      "Topic 8: 0.000*\"哼哼\" + 0.000*\"不能\" + 0.000*\"一樣\" + 0.000*\"時間\"\n",
      "Topic 9: 0.005*\"一樣\" + 0.005*\"面試\" + 0.005*\"問題\" + 0.005*\"想要\"\n",
      "Topic 10: 0.001*\"哼哼\" + 0.000*\"小時候\" + 0.000*\"如果\" + 0.000*\"發現\"\n",
      "Topic 11: 0.015*\"遊戲\" + 0.005*\"發現\" + 0.005*\"刷牙\" + 0.005*\"一樣\"\n",
      "Topic 12: 0.028*\"哼哼\" + 0.007*\"老師\" + 0.006*\"第一\" + 0.006*\"學校\"\n",
      "Topic 13: 0.016*\"小時候\" + 0.013*\"小孩\" + 0.009*\"打電動\" + 0.008*\"發現\"\n",
      "Topic 14: 0.013*\"金門\" + 0.007*\"印象\" + 0.006*\"一樣\" + 0.005*\"小時候\"\n",
      "Topic 15: 0.012*\"阿公\" + 0.008*\"阿嬤\" + 0.006*\"一樣\" + 0.005*\"奶奶\"\n",
      "Topic 16: 0.009*\"大便\" + 0.008*\"上廁所\" + 0.007*\"問題\" + 0.006*\"褲子\"\n",
      "Topic 17: 0.010*\"蜈蚣\" + 0.009*\"蟑螂\" + 0.006*\"壁虎\" + 0.005*\"登登\"\n",
      "Topic 18: 0.000*\"一樣\" + 0.000*\"如果\" + 0.000*\"問題\" + 0.000*\"發現\"\n",
      "Topic 19: 0.000*\"一樣\" + 0.000*\"小時候\" + 0.000*\"老師\" + 0.000*\"小孩\"\n",
      "Topic 20: 0.001*\"哼哼\" + 0.000*\"如果\" + 0.000*\"遊戲\" + 0.000*\"第一\"\n"
     ]
    }
   ],
   "source": [
    "# LDA\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "\n",
    "texts = [[word for word in ep['words'] if word not in stopwords and len(word) > 1] for ep in episodes]\n",
    "id2word = corpora.Dictionary(texts)\n",
    "\n",
    "# Create a document-term matrix\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Step 3: Build the LDA model\n",
    "lda_model = LdaModel(corpus=corpus, id2word=id2word, num_topics=20, random_state=42, passes=10)\n",
    "\n",
    "# Step 4: Print the topics with the top words for each topic\n",
    "for idx, topic in lda_model.print_topics(num_words=4):\n",
    "    print(f\"Topic {idx+1}: {topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd3e19e-1cee-4f0d-bd11-6ab7207f6789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
